{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet Segmentation New (3) ",
      "provenance": [],
      "authorship_tag": "ABX9TyMRPCfH7ydnG4Vw99s0Azpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angana1/Image-Segmentation/blob/main/Unet_Segmentation_New_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlxZc1Vdx76V"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBSviuN9jkrO"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BWoxQTUjnFI"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQISMXIfGI8P"
      },
      "source": [
        "def conv_block(inputs, filters, pool=True):\n",
        "    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    if pool == True:\n",
        "        p = MaxPool2D((2, 2))(x)\n",
        "        return x, p\n",
        "    else:\n",
        "        return x\n",
        "        \n",
        "def build_unet(shape, num_classes):\n",
        "    inputs = Input(shape)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    x1, p1 = conv_block(inputs, 16, pool=True)\n",
        "    x2, p2 = conv_block(p1, 32, pool=True)\n",
        "    x3, p3 = conv_block(p2, 48, pool=True)\n",
        "    x4, p4 = conv_block(p3, 64, pool=True)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = conv_block(p4, 128, pool=False)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
        "    c1 = Concatenate()([u1, x4])\n",
        "    x5 = conv_block(c1, 64, pool=False)\n",
        "\n",
        "    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
        "    c2 = Concatenate()([u2, x3])\n",
        "    x6 = conv_block(c2, 48, pool=False)\n",
        "\n",
        "    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
        "    c3 = Concatenate()([u3, x2])\n",
        "    x7 = conv_block(c3, 32, pool=False)\n",
        "\n",
        "    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
        "    c4 = Concatenate()([u4, x1])\n",
        "    x8 = conv_block(c4, 16, pool=False)\n",
        "\n",
        "    \"\"\" Output layer \"\"\"\n",
        "    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
        "\n",
        "    return Model(inputs, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXTRVduhGSQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1fd728-b14e-4d65-aedb-09869712c74a"
      },
      "source": [
        "model = build_unet((256, 256, 3), 3)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 48)   13872       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 48)   192         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 48)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 48)   20784       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 48)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   27712       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36928       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 32, 32, 128)  0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 192)  0           up_sampling2d[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 64)   110656      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 64)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 112)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 48)   48432       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 64, 64, 48)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 64, 64, 48)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 48)   20784       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 64, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 48) 0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 80) 0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 32) 23072       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 128, 128, 32) 128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128, 128, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 32) 9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 32) 0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 48) 0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 16) 6928        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 256, 256, 16) 64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 256, 256, 16) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 16) 2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 3)  51          activation_17[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 599,395\n",
            "Trainable params: 597,603\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUOaZHkQMJNv"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBt9rJ27GrMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "13f4a8ca-e569-4c36-fee3-45b35a664f7a"
      },
      "source": [
        "train_x=[]\n",
        "train_y=[]\n",
        "valid_x=[]\n",
        "valid_y=[]\n",
        "\n",
        "#Train set : 55/60 images (i -> 0 to 54)\n",
        "for i in range(55):\n",
        "  s1='/content/img/sample_'+str(i+1)+'.JPG';\n",
        "  train_x.append(s1)\n",
        "  s2='/content/gt/sample_'+str(i+1)+'.JPG';\n",
        "  train_y.append(s2)\n",
        "\n",
        "#Test set : 5/60 images (i-> 56 to 60)\n",
        "for i in range(55,60):\n",
        "  s1='/content/img/sample_'+str(i+1)+'.JPG';\n",
        "  valid_x.append(s1)\n",
        "  s2='/content/gt/sample_'+str(i+1)+'.JPG';\n",
        "  valid_y.append(s2)\n",
        "\n",
        "\n",
        "'''train_x=['/content/img/sample_1.JPG','/content/img/sample_2.JPG','/content/img/sample_3.JPG','/content/img/sample_4.JPG','/content/img/sample_5.JPG',\n",
        "         '/content/img/sample_6.JPG','/content/img/sample_7.JPG','/content/img/sample_8.JPG','/content/img/sample_9.JPG']\n",
        "train_y=['/content/gt/sample_1.JPG','/content/gt/sample_2.JPG','/content/gt/sample_3.JPG','/content/gt/sample_4.JPG',\n",
        "          '/content/gt/sample_5.JPG','/content/gt/sample_6.JPG','/content/gt/sample_7.JPG','/content/gt/sample_8.JPG','/content/gt/sample_9.JPG']\n",
        "valid_x=['/content/img/sample_10.JPG']\n",
        "valid_y=['/content/gt/sample_10.JPG']'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train_x=['/content/img/sample_1.JPG','/content/img/sample_2.JPG','/content/img/sample_3.JPG','/content/img/sample_4.JPG','/content/img/sample_5.JPG',\\n         '/content/img/sample_6.JPG','/content/img/sample_7.JPG','/content/img/sample_8.JPG','/content/img/sample_9.JPG']\\ntrain_y=['/content/gt/sample_1.JPG','/content/gt/sample_2.JPG','/content/gt/sample_3.JPG','/content/gt/sample_4.JPG',\\n          '/content/gt/sample_5.JPG','/content/gt/sample_6.JPG','/content/gt/sample_7.JPG','/content/gt/sample_8.JPG','/content/gt/sample_9.JPG']\\nvalid_x=['/content/img/sample_10.JPG']\\nvalid_y=['/content/gt/sample_10.JPG']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ik5zWv6ftA2",
        "outputId": "56638fd7-550b-42fc-cfbb-a96c24b6207a"
      },
      "source": [
        "print(valid_x, len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/img/sample_56.JPG', '/content/img/sample_57.JPG', '/content/img/sample_58.JPG', '/content/img/sample_59.JPG', '/content/img/sample_60.JPG'] 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0YCaJelMQ1i"
      },
      "source": [
        "H = 256\n",
        "W = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3USLjNVMAez"
      },
      "source": [
        "def read_image(x):\n",
        "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(x):\n",
        "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return x\n",
        "\n",
        "def tf_dataset(x, y, batch=1):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    #dataset = dataset.shuffle(buffer_size=5000)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.batch(batch)\n",
        "    #dataset = dataset.repeat()\n",
        "    #dataset = dataset.prefetch(2)\n",
        "    return dataset\n",
        "\n",
        "def preprocess(x, y):\n",
        "    def f(x, y):\n",
        "        x = x.decode()\n",
        "        y = y.decode()\n",
        "\n",
        "        image = read_image(x)\n",
        "        mask = read_mask(y)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n",
        "    #mask = tf.one_hot(mask, 3, dtype=tf.int32)\n",
        "    image.set_shape([H, W, 3])\n",
        "    mask.set_shape([H, W, 3])\n",
        "\n",
        "    return image, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OzoBvxYM1yo",
        "outputId": "46a09a44-3f5e-43ee-c0c5-22a96fa8410b"
      },
      "source": [
        "dataset = tf_dataset(train_x, train_y, batch=1)\n",
        "print(len(dataset))\n",
        "for x, y in dataset:\n",
        "  print(x.shape, y.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n",
            "(1, 256, 256, 3) (1, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFf_KxbwvRt9",
        "outputId": "d6ed7496-256a-4356-cad2-892aa881dd45"
      },
      "source": [
        "print(len(dataset))\n",
        "#dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjE0yntaNqZc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjyjunzCNsPu"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GI_QRhXOimR"
      },
      "source": [
        "shape = (256, 256, 3)\n",
        "num_classes = 3\n",
        "lr = 1e-2\n",
        "batch_size = 1\n",
        "epochs = 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iMgSgkqO2Gs"
      },
      "source": [
        " \"\"\" Model \"\"\"\n",
        "model = build_unet(shape, num_classes)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcSXbDzhO-e6"
      },
      "source": [
        "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
        "train_steps = len(train_x)//batch_size   #number of batches\n",
        "valid_steps = len(valid_x)//batch_size   #number of batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rbTGN_FPTOl"
      },
      "source": [
        "callbacks = [\n",
        "        ModelCheckpoint(\"/content/model.h5\", verbose=1, save_best_model=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-4)\n",
        "     \n",
        "    ]\n",
        "# EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wIuXor23hKcU",
        "outputId": "fd7444e5-4447-45af-89e9-4ee1f2332e4e"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geA6_XGGPgYU",
        "outputId": "4569644d-f3f9-427c-cee9-61a57ccc3ea2"
      },
      "source": [
        "model.fit(train_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_data=valid_dataset,\n",
        "        validation_steps=valid_steps,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "55/55 [==============================] - 35s 58ms/step - loss: 0.2910 - val_loss: 287.0493\n",
            "\n",
            "Epoch 00001: saving model to /content/model.h5\n",
            "Epoch 2/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2846 - val_loss: 102.6596\n",
            "\n",
            "Epoch 00002: saving model to /content/model.h5\n",
            "Epoch 3/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2851 - val_loss: 5.3432\n",
            "\n",
            "Epoch 00003: saving model to /content/model.h5\n",
            "Epoch 4/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2836 - val_loss: 0.3305\n",
            "\n",
            "Epoch 00004: saving model to /content/model.h5\n",
            "Epoch 5/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2826 - val_loss: 4.0717\n",
            "\n",
            "Epoch 00005: saving model to /content/model.h5\n",
            "Epoch 6/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2791 - val_loss: 0.5815\n",
            "\n",
            "Epoch 00006: saving model to /content/model.h5\n",
            "Epoch 7/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2813 - val_loss: 0.3028\n",
            "\n",
            "Epoch 00007: saving model to /content/model.h5\n",
            "Epoch 8/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2805 - val_loss: 0.2897\n",
            "\n",
            "Epoch 00008: saving model to /content/model.h5\n",
            "Epoch 9/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2795 - val_loss: 0.2890\n",
            "\n",
            "Epoch 00009: saving model to /content/model.h5\n",
            "Epoch 10/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2791 - val_loss: 0.3875\n",
            "\n",
            "Epoch 00010: saving model to /content/model.h5\n",
            "Epoch 11/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2795 - val_loss: 0.3198\n",
            "\n",
            "Epoch 00011: saving model to /content/model.h5\n",
            "Epoch 12/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2780 - val_loss: 0.2877\n",
            "\n",
            "Epoch 00012: saving model to /content/model.h5\n",
            "Epoch 13/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2778 - val_loss: 0.2820\n",
            "\n",
            "Epoch 00013: saving model to /content/model.h5\n",
            "Epoch 14/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2776 - val_loss: 0.2886\n",
            "\n",
            "Epoch 00014: saving model to /content/model.h5\n",
            "Epoch 15/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2768 - val_loss: 0.2766\n",
            "\n",
            "Epoch 00015: saving model to /content/model.h5\n",
            "Epoch 16/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2763 - val_loss: 0.2770\n",
            "\n",
            "Epoch 00016: saving model to /content/model.h5\n",
            "Epoch 17/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2761 - val_loss: 0.3638\n",
            "\n",
            "Epoch 00017: saving model to /content/model.h5\n",
            "Epoch 18/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2764 - val_loss: 0.4289\n",
            "\n",
            "Epoch 00018: saving model to /content/model.h5\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 19/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2766 - val_loss: 0.3176\n",
            "\n",
            "Epoch 00019: saving model to /content/model.h5\n",
            "Epoch 20/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2755 - val_loss: 0.2779\n",
            "\n",
            "Epoch 00020: saving model to /content/model.h5\n",
            "Epoch 21/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2755 - val_loss: 0.2735\n",
            "\n",
            "Epoch 00021: saving model to /content/model.h5\n",
            "Epoch 22/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2753 - val_loss: 0.2735\n",
            "\n",
            "Epoch 00022: saving model to /content/model.h5\n",
            "Epoch 23/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2752 - val_loss: 0.2733\n",
            "\n",
            "Epoch 00023: saving model to /content/model.h5\n",
            "Epoch 24/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2750 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00024: saving model to /content/model.h5\n",
            "Epoch 25/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2749 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00025: saving model to /content/model.h5\n",
            "Epoch 26/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2746 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00026: saving model to /content/model.h5\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 27/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2744 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00027: saving model to /content/model.h5\n",
            "Epoch 28/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2742 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00028: saving model to /content/model.h5\n",
            "Epoch 29/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2741 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00029: saving model to /content/model.h5\n",
            "Epoch 30/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00030: saving model to /content/model.h5\n",
            "Epoch 31/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00031: saving model to /content/model.h5\n",
            "Epoch 32/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2739 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00032: saving model to /content/model.h5\n",
            "Epoch 33/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00033: saving model to /content/model.h5\n",
            "Epoch 34/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00034: saving model to /content/model.h5\n",
            "Epoch 35/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2742\n",
            "\n",
            "Epoch 00035: saving model to /content/model.h5\n",
            "Epoch 36/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00036: saving model to /content/model.h5\n",
            "Epoch 37/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2739 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00037: saving model to /content/model.h5\n",
            "Epoch 38/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2739 - val_loss: 0.2742\n",
            "\n",
            "Epoch 00038: saving model to /content/model.h5\n",
            "Epoch 39/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2739 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00039: saving model to /content/model.h5\n",
            "Epoch 40/100\n",
            "55/55 [==============================] - 3s 48ms/step - loss: 0.2740 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00040: saving model to /content/model.h5\n",
            "Epoch 41/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2739 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00041: saving model to /content/model.h5\n",
            "Epoch 42/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2740 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00042: saving model to /content/model.h5\n",
            "Epoch 43/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2739 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00043: saving model to /content/model.h5\n",
            "Epoch 44/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2739 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00044: saving model to /content/model.h5\n",
            "Epoch 45/100\n",
            "55/55 [==============================] - 3s 51ms/step - loss: 0.2739 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00045: saving model to /content/model.h5\n",
            "Epoch 46/100\n",
            "55/55 [==============================] - 3s 51ms/step - loss: 0.2738 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00046: saving model to /content/model.h5\n",
            "Epoch 47/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2738 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00047: saving model to /content/model.h5\n",
            "Epoch 48/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2737 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00048: saving model to /content/model.h5\n",
            "Epoch 49/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2738 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00049: saving model to /content/model.h5\n",
            "Epoch 50/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2737 - val_loss: 0.2741\n",
            "\n",
            "Epoch 00050: saving model to /content/model.h5\n",
            "Epoch 51/100\n",
            "55/55 [==============================] - 3s 51ms/step - loss: 0.2737 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00051: saving model to /content/model.h5\n",
            "Epoch 52/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2736 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00052: saving model to /content/model.h5\n",
            "Epoch 53/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2737 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00053: saving model to /content/model.h5\n",
            "Epoch 54/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2735 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00054: saving model to /content/model.h5\n",
            "Epoch 55/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2735 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00055: saving model to /content/model.h5\n",
            "Epoch 56/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2734 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00056: saving model to /content/model.h5\n",
            "Epoch 57/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2735 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00057: saving model to /content/model.h5\n",
            "Epoch 58/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2733 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00058: saving model to /content/model.h5\n",
            "Epoch 59/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2733 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00059: saving model to /content/model.h5\n",
            "Epoch 60/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2733 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00060: saving model to /content/model.h5\n",
            "Epoch 61/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2733 - val_loss: 0.2740\n",
            "\n",
            "Epoch 00061: saving model to /content/model.h5\n",
            "Epoch 62/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2733 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00062: saving model to /content/model.h5\n",
            "Epoch 63/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2733 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00063: saving model to /content/model.h5\n",
            "Epoch 64/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2732 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00064: saving model to /content/model.h5\n",
            "Epoch 65/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2732 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00065: saving model to /content/model.h5\n",
            "Epoch 66/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2732 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00066: saving model to /content/model.h5\n",
            "Epoch 67/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2731 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00067: saving model to /content/model.h5\n",
            "Epoch 68/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2731 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00068: saving model to /content/model.h5\n",
            "Epoch 69/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2731 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00069: saving model to /content/model.h5\n",
            "Epoch 70/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2730 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00070: saving model to /content/model.h5\n",
            "Epoch 71/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2730 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00071: saving model to /content/model.h5\n",
            "Epoch 72/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2730 - val_loss: 0.2739\n",
            "\n",
            "Epoch 00072: saving model to /content/model.h5\n",
            "Epoch 73/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2729 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00073: saving model to /content/model.h5\n",
            "Epoch 74/100\n",
            "55/55 [==============================] - 3s 51ms/step - loss: 0.2729 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00074: saving model to /content/model.h5\n",
            "Epoch 75/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2729 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00075: saving model to /content/model.h5\n",
            "Epoch 76/100\n",
            "55/55 [==============================] - 3s 51ms/step - loss: 0.2729 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00076: saving model to /content/model.h5\n",
            "Epoch 77/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2728 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00077: saving model to /content/model.h5\n",
            "Epoch 78/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2728 - val_loss: 0.2738\n",
            "\n",
            "Epoch 00078: saving model to /content/model.h5\n",
            "Epoch 79/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2728 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00079: saving model to /content/model.h5\n",
            "Epoch 80/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2728 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00080: saving model to /content/model.h5\n",
            "Epoch 81/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2728 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00081: saving model to /content/model.h5\n",
            "Epoch 82/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2727 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00082: saving model to /content/model.h5\n",
            "Epoch 83/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2727 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00083: saving model to /content/model.h5\n",
            "Epoch 84/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2726 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00084: saving model to /content/model.h5\n",
            "Epoch 85/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2726 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00085: saving model to /content/model.h5\n",
            "Epoch 86/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2726 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00086: saving model to /content/model.h5\n",
            "Epoch 87/100\n",
            "55/55 [==============================] - 3s 51ms/step - loss: 0.2726 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00087: saving model to /content/model.h5\n",
            "Epoch 88/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2726 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00088: saving model to /content/model.h5\n",
            "Epoch 89/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2726 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00089: saving model to /content/model.h5\n",
            "Epoch 90/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2726 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00090: saving model to /content/model.h5\n",
            "Epoch 91/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2726 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00091: saving model to /content/model.h5\n",
            "Epoch 92/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2725 - val_loss: 0.2735\n",
            "\n",
            "Epoch 00092: saving model to /content/model.h5\n",
            "Epoch 93/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2725 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00093: saving model to /content/model.h5\n",
            "Epoch 94/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2725 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00094: saving model to /content/model.h5\n",
            "Epoch 95/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2725 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00095: saving model to /content/model.h5\n",
            "Epoch 96/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2725 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00096: saving model to /content/model.h5\n",
            "Epoch 97/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2726 - val_loss: 0.2736\n",
            "\n",
            "Epoch 00097: saving model to /content/model.h5\n",
            "Epoch 98/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2725 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00098: saving model to /content/model.h5\n",
            "Epoch 99/100\n",
            "55/55 [==============================] - 3s 49ms/step - loss: 0.2726 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00099: saving model to /content/model.h5\n",
            "Epoch 100/100\n",
            "55/55 [==============================] - 3s 50ms/step - loss: 0.2726 - val_loss: 0.2737\n",
            "\n",
            "Epoch 00100: saving model to /content/model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5cb055c250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TlGd4U9P19W"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVreeywUQFy_"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1QnRNzaP3jV",
        "outputId": "7fbee44b-fa83-406c-d3f7-708d9e2e2297"
      },
      "source": [
        "for x, y in tqdm(zip(valid_x, valid_y), total=len(valid_x)):\n",
        "        name = x.split(\"/\")[-1]\n",
        "\n",
        "        ## Read image\n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        x = cv2.resize(x, (W, H))\n",
        "        x = x / 255.0\n",
        "        x = x.astype(np.float32)\n",
        "        print('shape of x',x.shape)\n",
        "\n",
        "        ## Read mask\n",
        "        y = cv2.imread(y, cv2.IMREAD_COLOR)\n",
        "        y = cv2.resize(y, (W, H))\n",
        "        y = y / 255.0\n",
        "        y = y.astype(np.float32)\n",
        "        print('shape of y',y.shape)\n",
        "        '''y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "        y = cv2.resize(y, (W, H))   ## (256, 256)\n",
        "        y = y - 1\n",
        "        y = np.expand_dims(y, axis=-1) ## (256, 256, 1)\n",
        "        y = y * (255/num_classes)\n",
        "        y = y.astype(np.int32)\n",
        "        y = np.concatenate([y, y, y], axis=2)'''\n",
        "\n",
        "        ## Prediction\n",
        "        p = model.predict(np.expand_dims(x, axis=0))\n",
        "        print('shape 1:',p.shape )\n",
        "        p = np.argmax(p, axis=-1)\n",
        "        print('shape 2:',p.shape )\n",
        "        p = np.expand_dims(p, axis=-1)\n",
        "        print('shape 3:',p.shape )\n",
        "        p = p * (255/num_classes)\n",
        "        print('shape 4:',p.shape )\n",
        "        p = p.astype(np.int32)\n",
        "        #p = np.concatenate([p, p, p], axis=2)\n",
        "\n",
        "\n",
        "\n",
        "        x = x * 255.0\n",
        "        x = x.astype(np.int32)\n",
        "\n",
        "        h, w, _ = x.shape\n",
        "        line = np.ones((h, 10, 3)) * 255\n",
        "\n",
        "        # print(x.shape, line.shape, y.shape, line.shape, p.shape)\n",
        "\n",
        "        #final_image = np.concatenate([x, line, y, line, p], axis=1)\n",
        "        final_image=p[0]\n",
        "        print('shape of p',p.shape)\n",
        "        print('shape of final image',final_image.shape)\n",
        "        cv2.imwrite(f\"/content/results/{name}\", final_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape of x (256, 256, 3)\n",
            "shape of y (256, 256, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:00<00:00,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape 1: (1, 256, 256, 3)\n",
            "shape 2: (1, 256, 256)\n",
            "shape 3: (1, 256, 256, 1)\n",
            "shape 4: (1, 256, 256, 1)\n",
            "shape of p (1, 256, 256, 1)\n",
            "shape of final image (256, 256, 1)\n",
            "shape of x (256, 256, 3)\n",
            "shape of y (256, 256, 3)\n",
            "shape 1: (1, 256, 256, 3)\n",
            "shape 2: (1, 256, 256)\n",
            "shape 3: (1, 256, 256, 1)\n",
            "shape 4: (1, 256, 256, 1)\n",
            "shape of p (1, 256, 256, 1)\n",
            "shape of final image (256, 256, 1)\n",
            "shape of x (256, 256, 3)\n",
            "shape of y (256, 256, 3)\n",
            "shape 1: (1, 256, 256, 3)\n",
            "shape 2: (1, 256, 256)\n",
            "shape 3: (1, 256, 256, 1)\n",
            "shape 4: (1, 256, 256, 1)\n",
            "shape of p (1, 256, 256, 1)\n",
            "shape of final image (256, 256, 1)\n",
            "shape of x (256, 256, 3)\n",
            "shape of y (256, 256, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00,  6.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape 1: (1, 256, 256, 3)\n",
            "shape 2: (1, 256, 256)\n",
            "shape 3: (1, 256, 256, 1)\n",
            "shape 4: (1, 256, 256, 1)\n",
            "shape of p (1, 256, 256, 1)\n",
            "shape of final image (256, 256, 1)\n",
            "shape of x (256, 256, 3)\n",
            "shape of y (256, 256, 3)\n",
            "shape 1: (1, 256, 256, 3)\n",
            "shape 2: (1, 256, 256)\n",
            "shape 3: (1, 256, 256, 1)\n",
            "shape 4: (1, 256, 256, 1)\n",
            "shape of p (1, 256, 256, 1)\n",
            "shape of final image (256, 256, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KFgcXOaR1LQ"
      },
      "source": [
        "#final_image = np.concatenate([line, p], axis=1)\n",
        "#cv2.imwrite(\"/content/results.JPG\", final_image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}